# Applications

## Examples and Intuitions I

A simple example of applying neural networks is by predicting $x_1$ AND $x_2$, which is the logical 'and' operator and is only true if both $x_1$ and $x_2$ are 1.

The graph of our functions will look like:

![avatar](https://raw.githubusercontent.com/garyphone/machine_learning/master/pictures/l4_5.PNG)

Remember that $x_0$ is our bias variable and is always 1.

Let's set our first theta matrix as:

$$
\Theta^{(1)}=[-30\ 20\ 20]
$$

This will cause the output of our hypothesis to only be positive if both $x_1$ and $x_2$ are 1. In other words:

$$
h_\Theta (x)=g(-30+20x_1+20x_2)
$$

$$
x_1=0 \text{ and } x_2=0 \text{ then } g(-30) ≈ 0
$$

$$
x_1=0 \text{ and } x_2=1 \text{ then } g(-10) ≈ 0
$$

$$
x_1=1 \text{ and } x_2=0 \text{ then } g(-10) ≈ 0
$$

$$
x_1=1 \text{ and } x_2=1 \text{ then } g(10) ≈ 1
$$

So we have constructed one of the fundamental operations in computers by using a small neural network rather than using an actual AND gate. Neural networks can also be used to simulate all the other logical gates.

## Examples and Intuitions II

The $\Theta^{(1)}$ matrices for AND, NOR, and OR are:

$$
\textbf{AND: } \Theta^{(1)}=[-30\ 20\ 20]
$$

$$
\textbf{NOR: } \Theta^{(1)}=[10\ -20\ -20]
$$

$$
\textbf{OR: } \Theta^{(1)}=[-10\ 20\ 20]
$$

We can combine these to get the XNOR logical operator (which gives 1 if $x_1$ and $x_2$ are both 0 or both 1).

![avatar](https://raw.githubusercontent.com/garyphone/machine_learning/master/pictures/l4_6.PNG)

For the transition between the first and second layer, we'll use a $\Theta^{(1)}$ matrix that combines the values for AND and NOR:

$$
\Theta^{(1)}=[−30\ 10\ 20 \\ −20\ 20\ −20]
$$

For the transition between the second and third layer, we'll use a $\Theta^{(2)}$ matrix that uses the value for OR:

$$
\Theta^{(2)}=[−10\ 20\ 20]
$$

Let's write out the values for all our nodes:

$$
a^{(2)}=g(\Theta^{(1)}\cdot x)
$$

$$
a^{(3)}=g(\Theta^{(2)}\cdot a^{(2)})
$$

$$
h_{\Theta}(x)=a^{(3)}
$$

And there we have the XNOR operator using a hidden layer with two nodes!
